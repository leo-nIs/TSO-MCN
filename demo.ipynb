{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6bfb858-d336-4e9a-8876-8e8913d3663e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import MeanShift\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import warnings\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, recall_score, precision_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import xgboost as xgb\n",
    "from typing import List, Tuple\n",
    "from numpy import arange, argsort, argwhere, empty, full, inf, intersect1d, max, ndarray, sort, sum, zeros\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92ad4bcb-5704-4f55-813b-b9441a916a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def averageDis(distance):\n",
    "    sum = 0\n",
    "    for i in range(len(distance)):\n",
    "        for j in range(len(distance)):\n",
    "            if j < i:\n",
    "                sum += distance[i][j]\n",
    "    return sum / len(distance)\n",
    "\n",
    "def getCentroid(point):\n",
    "    random_factor = 1\n",
    "    point_array = np.array(point) * random_factor\n",
    "    return np.mean(point_array, 0).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffed59d4-ca39-47eb-814d-26a493b01ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GIN_DPC(k: int, nc: int, data: ndarray) -> Tuple[ndarray, ndarray]:\n",
    "    unassigned = -1\n",
    "\n",
    "    n, d = data.shape\n",
    "\n",
    "    # Compute distance\n",
    "    distance = squareform(pdist(data))\n",
    "\n",
    "    # Compute neighbor\n",
    "    indexDistanceAsc: ndarray = argsort(distance)\n",
    "    indexNeighbor: ndarray = indexDistanceAsc[:, :k]\n",
    "\n",
    "    # Compute shared neighbor\n",
    "    indexSharedNeighbor = empty([n, n, k], int)\n",
    "    numSharedNeighbor = empty([n, n], int)\n",
    "    for i in range(n):\n",
    "        numSharedNeighbor[i, i] = 0\n",
    "        for j in range(i):\n",
    "            shared: ndarray = intersect1d(indexNeighbor[i], indexNeighbor[j], assume_unique=True)\n",
    "            numSharedNeighbor[j, i] = numSharedNeighbor[i, j] = shared.size\n",
    "            indexSharedNeighbor[j, i, :shared.size] = indexSharedNeighbor[i, j, :shared.size] = shared\n",
    "\n",
    "    # Compute similarity\n",
    "    similarity = zeros([n, n])\n",
    "    for i in range(n):\n",
    "        for j in range(i):\n",
    "            if i in indexSharedNeighbor[i, j] and j in indexSharedNeighbor[i, j]:\n",
    "                indexShared = indexSharedNeighbor[i, j, :numSharedNeighbor[i, j]]\n",
    "                distanceSum = sum(distance[i, indexShared] * distance[j, indexShared])\n",
    "                similarity[i, j] = similarity[j, i] = numSharedNeighbor[i, j] ** 4 / (distanceSum * (distance[i, j] ** 2))\n",
    "\n",
    "    rho = sum(sort(similarity)[:, -k:], axis=1)\n",
    "\n",
    "    distanceNeighborSum = empty(n)\n",
    "    for i in range(n):\n",
    "        distanceNeighborSum[i] = sum(distance[i, indexNeighbor[i]])\n",
    "    indexRhoDesc = argsort(rho)[::-1]\n",
    "    delta = full(n, inf)\n",
    "    for i, a in enumerate(indexRhoDesc[1:], 1):\n",
    "        for b in indexRhoDesc[:i]:\n",
    "            delta[a] = min(delta[a], distance[a, b] * (distanceNeighborSum[a] + distanceNeighborSum[b]))\n",
    "    delta[indexRhoDesc[0]] = -inf\n",
    "    delta[indexRhoDesc[0]] = max(delta)\n",
    "    gamma = rho * delta\n",
    "    indexAssignment = full(n, unassigned)\n",
    "    indexCentroid: ndarray = sort(argsort(gamma)[-nc:])\n",
    "    indexAssignment[indexCentroid] = arange(nc)\n",
    "\n",
    "    queue: List[int] = indexCentroid.tolist()\n",
    "    while queue:\n",
    "        a = queue.pop(0)\n",
    "        for b in indexNeighbor[a]:\n",
    "            if indexAssignment[b] == unassigned and numSharedNeighbor[a, b] >= k / 2:\n",
    "                indexAssignment[b] = indexAssignment[a]\n",
    "                queue.append(b)\n",
    "\n",
    "    indexUnassigned = argwhere(indexAssignment == unassigned).flatten()\n",
    "    while indexUnassigned.size:\n",
    "        numNeighborAssignment = zeros([indexUnassigned.size, nc], int)\n",
    "        for i, a in enumerate(indexUnassigned):\n",
    "            for b in indexDistanceAsc[a, :k]:\n",
    "                if indexAssignment[b] != unassigned:\n",
    "                    numNeighborAssignment[i, indexAssignment[b]] += 1\n",
    "        if most := max(numNeighborAssignment):\n",
    "            temp = argwhere(numNeighborAssignment == most)\n",
    "            indexAssignment[indexUnassigned[temp[:, 0]]] = temp[:, 1]\n",
    "            indexUnassigned = argwhere(indexAssignment == unassigned).flatten()\n",
    "        else:\n",
    "            k += 1\n",
    "\n",
    "    return indexCentroid, indexAssignment, indexNeighbor, numSharedNeighbor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47445904-5366-4560-974d-13575228be47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TSO_MCN(X_train, y_train, cluster=3, K=6):\n",
    "\n",
    "    indices_class_1 = np.where(y_train == 1)[0]\n",
    "    # print(type(X_train))\n",
    "    X_train_class_1 = X_train.iloc[indices_class_1]\n",
    "\n",
    "    gmm = GaussianMixture(n_components=cluster, random_state=42)\n",
    "    gmm.fit(X_train_class_1)\n",
    "    gmm_labels = gmm.predict(X_train_class_1)\n",
    "    gmm_centers = gmm.means_\n",
    "\n",
    "    kmeans = KMeans(n_clusters=cluster, random_state=42)\n",
    "    kmeans.fit(X_train_class_1)\n",
    "    kmeans_labels = kmeans.predict(X_train_class_1)\n",
    "    kmeans_centers = kmeans.cluster_centers_\n",
    "\n",
    "    mean_shift = MeanShift()\n",
    "    mean_shift.fit(X_train_class_1)\n",
    "    mean_shift_labels = mean_shift.labels_\n",
    "    mean_shift_centers = mean_shift.cluster_centers_\n",
    "\n",
    "    X_train_with_centers = np.vstack([X_train.values, gmm_centers])\n",
    "    y_train_with_centers = np.concatenate([y_train, np.ones(gmm_centers.shape[0])])\n",
    "\n",
    "    X_train_with_centers = np.vstack([X_train_with_centers, kmeans_centers])\n",
    "    y_train_with_centers = np.concatenate([y_train_with_centers, np.ones(kmeans_centers.shape[0])])\n",
    "\n",
    "    X_train_with_centers = np.vstack([X_train_with_centers, mean_shift_centers])\n",
    "    y_train_with_centers = np.concatenate([y_train_with_centers, np.ones(mean_shift_centers.shape[0])])\n",
    "\n",
    "    minority_class_count = (y_train_with_centers == 1).sum()\n",
    "    majority_class_count = (y_train_with_centers == 0).sum()\n",
    "\n",
    "    minority_class_indices = np.where(y_train_with_centers == 1)[0]\n",
    "    X_train_minority_class = X_train_with_centers[minority_class_indices]\n",
    "\n",
    "    P_array = X_train_minority_class\n",
    "    G = majority_class_count - minority_class_count\n",
    "    P_index = minority_class_indices\n",
    "\n",
    "    # GIN_DPC\n",
    "    centroid, assignment, indexNeighbor, numSharedNeighbor = GIN_DPC(K, cluster, P_array)\n",
    "\n",
    "    centroid = centroid.tolist()\n",
    "    assignment = assignment.tolist()\n",
    "    numSharedNeighbor_vector = numSharedNeighbor\n",
    "\n",
    "    SimilarNeighbor_K = int(K / 2) + 1\n",
    "    SimilarNeighbor_vector_indices = [[] for _ in range(len(centroid))]\n",
    "\n",
    "    for i in range(len(numSharedNeighbor_vector)):\n",
    "        for j in range(i + 1, len(numSharedNeighbor_vector[i])):\n",
    "            if numSharedNeighbor_vector[i][j] > SimilarNeighbor_K and assignment[i] == assignment[j]:\n",
    "                SimilarNeighbor_vector_indices[assignment[i]].append((i, j, numSharedNeighbor_vector[i][j]))\n",
    "\n",
    "    sorted_SimilarNeighbor_vector_indices = [\n",
    "        sorted(row, key=lambda x: x[2], reverse=True) for row in SimilarNeighbor_vector_indices\n",
    "    ]\n",
    "    cleaned_sorted_SimV = [[(x[0], x[1]) for x in row] for row in sorted_SimilarNeighbor_vector_indices]\n",
    "\n",
    "    P_assignment = [[] for _ in range(len(centroid))]\n",
    "    for index in range(len(P_array)):\n",
    "        if index not in indexNeighbor[assignment[index]]:\n",
    "            P_assignment[assignment[index]].append(P_array[index])\n",
    "\n",
    "    weight = []\n",
    "    for index in range(len(centroid)):\n",
    "        count = assignment.count(index)\n",
    "        weight.append(count / majority_class_count)\n",
    "\n",
    "    syn_num = [int(w * G) for w in weight]\n",
    "\n",
    "    Synthetic = []\n",
    "    np.random.seed(42)\n",
    "\n",
    "    for index in range(len(centroid)):\n",
    "        selected_points = set()\n",
    "        arr_P = np.array(P_assignment[index])\n",
    "        SimVnum = 0\n",
    "\n",
    "        for num in range(syn_num[index]):\n",
    "            available_points = [tuple(pt) for pt in arr_P if tuple(pt) not in selected_points]\n",
    "            if len(available_points) == 0:\n",
    "                if len(cleaned_sorted_SimV[index]) == 0:\n",
    "                    break\n",
    "                elif SimVnum < len(cleaned_sorted_SimV[index]):\n",
    "                    SimVnum_tuple = cleaned_sorted_SimV[index][SimVnum]\n",
    "                    Simpoint = [P_array[SimVnum_tuple[0]], P_array[SimVnum_tuple[1]]]\n",
    "                    synthetic = getCentroid(Simpoint)\n",
    "                    Synthetic.append(synthetic)\n",
    "                    SimVnum += 1\n",
    "                else:\n",
    "                    break\n",
    "            else:\n",
    "                if len(available_points) < 2:\n",
    "                    point = [available_points[np.random.choice(len(available_points))]]\n",
    "                else:\n",
    "                    idx = np.random.choice(len(available_points), 2, replace=False)\n",
    "                    point = [available_points[i] for i in idx]\n",
    "\n",
    "                for pt in point:\n",
    "                    selected_points.add(tuple(pt))\n",
    "\n",
    "                point.append(P_array[centroid[index]])\n",
    "                synthetic = getCentroid(point)\n",
    "                Synthetic.append(synthetic)\n",
    "\n",
    "    Synthetic = np.array(Synthetic)\n",
    "\n",
    "    X_csmote = np.r_[X_train_with_centers, Synthetic]\n",
    "    y_csmote = np.r_[np.array(y_train_with_centers).flatten(), np.ones(Synthetic.shape[0])]\n",
    "\n",
    "    return X_csmote, y_csmote\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9689d4bc-2837-475e-87f9-377bd73a61f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9634146341463415\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('.\\data\\led7digit-0-2-4-5-6-7-8-9_vs_1.dat')\n",
    "X = data.iloc[:, data.columns != \"Class\"]\n",
    "y = data[\"Class\"].values.ravel()   # 转为1维\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train_cv_TSO_MCN, y_train_cv_TSO_MCN = TSO_MCN(X_train, y_train)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_cv_TSO_MCN, y_train_cv_TSO_MCN)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1577ddd5-ac7c-4c81-95ed-16f924ae21b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
